model:
  name: "unsloth/Llama-3.2-1B"
  dtype: "bfloat16"

calib:
  data_path: "/share/a.ammar/sparsesvd/llama1b/data/calib/refinedweb"
  dataset: "refinedweb"
  num_samples: 256
  seq_len: 1024
  batch_size: 8
  seed: 2023

profiling:
  module_names:
    - "self_attn.q_proj"
    - "self_attn.k_proj"
    - "self_attn.v_proj"
    - "self_attn.o_proj"
    - "mlp.gate_proj"
    - "mlp.up_proj"
    - "mlp.down_proj"
  cr_candidates: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]
  ks_ratio: 2.0
  profile_cache: "./layer_prof_llama3_1b.json"

compression:
  target_kept_ratio: 0.50   
  param_precision: 50000
  dobi_like: false
  output_dir: "/share/a.ammar/swift_svd/llama3_1b_swift_svd_50"

evaluation:
  tasks: ["wikitext"]
  batch_size: 4
  max_batch_size: 16
  device: "cuda"