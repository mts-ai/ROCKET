model:
  name: "unsloth/Llama-3.2-1B"
  dtype: "bfloat16"

calib:
  data_path: "/share/a.ammar/sparsesvd/llama1b/data/calib/refinedweb"
  dataset: "refinedweb"
  num_samples: 256
  seq_len: 1024
  batch_size: 8
  seed: 2023

profiling:
  module_names:
    - "self_attn.q_proj"
    - "self_attn.k_proj"
    - "self_attn.v_proj"
    - "self_attn.o_proj"
    - "mlp.gate_proj"
    - "mlp.up_proj"
    - "mlp.down_proj"
  cr_candidates: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4] #, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]
  ks_ratio: 2.0
  profile_cache: "./layer_prof_llama3_1b_v2.json"

compression:
  target_kept_ratio: 0.20   
  param_precision: 50000
  dobi_like: false
  output_dir: "/share/a.ammar/swift_svd/llama3_1b_swift_svd_20_new"
  adam_refine_steps: 100

evaluation:
  tasks: ["wikitext"] #["mmlu", "arc_easy", "arc_challenge", "hellaswag", "piqa", "lambada_openai", "race", "sciq"] #
  batch_size: 4
  max_batch_size: 16
  device: "cuda"
